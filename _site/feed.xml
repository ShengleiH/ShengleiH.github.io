<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shenglei Sketches</title>
    <description>在机器学习的路上，装逼女青年 | I am learning machine learning | 最喜欢在咖啡店自习</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 27 Nov 2016 17:01:50 +0800</pubDate>
    <lastBuildDate>Sun, 27 Nov 2016 17:01:50 +0800</lastBuildDate>
    <generator>Jekyll v3.3.0</generator>
    
      <item>
        <title>TensorFlow图片数据读取和reshape</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://github.com/ShengleiH/machine_learning/blob/master/tensorflow/tutorials/cifar10/cifar10_input.py&quot;&gt;cnn中数据读取代码&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;confusing&quot;&gt;我认为最confusing的地方&lt;/h3&gt;

&lt;p&gt;为什么tf.train.shuffle_batch()函数的参数中，只输入了单张图片，但是在训练的时候却能够获取到一个图片batch呢？&lt;/p&gt;

&lt;p&gt;在代码中可以看到是这样用的：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;images, label_batch = tf.train.shuffle_batch(
    [image, label],
    batch_size=batch_size,
    num_threads=num_preprocess_threads,
    capacity=min_queue_examples + 3 * batch_size,
    min_after_dequeue=min_queue_examples
)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;很神奇地，输入的是[image, label]–单张图片，输出的却是images, label_batch–一个数据集。&lt;/p&gt;

&lt;p&gt;其实只是我们看上去是放入了一张图片，其实tensorflow对这个函数是这样理解的：shuffle_batch构建了一个RandomShuffleQueue，并不断地把单个的[image，label]对送入队列中，这个入队操作是通过QueueRunners启动另外的线程来完成的。这个RandomShuffleQueue会顺序地压样例到队列中，直到队列中的样例个数达到了batch_size+min_after_dequeue个。它然后从队列中选择batch_size个随机的元素进行返回。&lt;/p&gt;

&lt;p&gt;也就是说，有一个线程在训练开始后，不断地在调用read_cifar10()这个函数，从文件中不断地读取图片，送入队列，直到数量够为止。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文档：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://m.2cto.com/kf/201611/561584.html&quot;&gt;shuffle_batch运行原理&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;reshape&quot;&gt;数据读取和reshape详解&lt;/h3&gt;

&lt;p&gt;接下来，一点儿点儿来分解和数据读取有关的代码。它们分布在cifar10_input.py和cifar10_model.py中。&lt;/p&gt;

&lt;p&gt;cifar10_model.py是路径指定和数据下载，cifar10_input.py是数据读取和封装。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;下载CIFAR-10数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;方法一：手动下载，直接去&lt;a href=&quot;http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz&quot;&gt;http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz&lt;/a&gt;上下载这个压缩包。在工程目录下新建一个cifar10_data文件夹，把压缩包放到这个文件夹下。&lt;/p&gt;

&lt;p&gt;方法二：通过url远程下载&lt;/p&gt;

&lt;p&gt;这就需要用到python中的urllib包下的urlretrieve函数了 - &lt;strong&gt;urllib.request.urlretrieve(…)&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;API: 
urllib.request.urlretrieve(url, filepath=None, reporthook=None, data=None)

args:
url - 远程访问的地址
filepath - 保存到本地的路径，如果不指定，将自动生成一个临时路径
reporthook - 自定义的回调函数，当连接上服务器，而且相应的data传输完成时，将触发这个回调函数。
data - 要post到服务器的数据

return：
filepath: 如果没有filepath，那么将把临时路径返回，否则，就是那个指定路径
header：服务器端发过来的响应头

举个例子：
DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'
data_dir = 'cifar10_data'
filename = DATA_URL.split('/')[-1]
filepath = os.path.join(data_dir, filename)
filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, reporthook=None, data=None)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;官网中，给的data_dir是‘/tmp/cifar10_data’，这里的’/tmp’是&lt;strong&gt;系统&lt;/strong&gt;临时缓存路径，不是认为新建的，正常情况是隐藏的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;解压CIFAR-10数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不管是手动下载还是url下载，刚下载下来的是压缩包，所以我们要先解压，然后才能使用。&lt;/p&gt;

&lt;p&gt;方法一：手动解压，然后再把文件夹放到cifar10_data文件夹下。&lt;/p&gt;

&lt;p&gt;方法二：python代码解压&lt;/p&gt;

&lt;p&gt;需要用到python的tarfile包的open函数 - &lt;strong&gt;tarfile.open(…).extractall(…)&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;API:
tarfile.open(filepath, mode).extractall(dest_path)

args:
filepath - 需要解压的文件所在路径
mode - 解压的模式，如只读'r'，如读‘gz’后缀的压缩包‘r:gz’
dest_path - 解压到的路径

举个例子：
tarfile.open(filepath, ‘r:gz’).extractall(data_dir)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;至此为止，不管用的是哪一种方法，都应该在你的工程下有如下目录结构：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/in-post/catelog_struc.png&quot; alt=&quot;目录结构图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数据读取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;把数存放到合适的路径之后，就可以开始读取数据，以及数据的后续处理了。&lt;/p&gt;

&lt;p&gt;在cifar10_input.py文件中定义一个&lt;code class=&quot;highlighter-rouge&quot;&gt;distorted_inputs(data_dir, batch_size)&lt;/code&gt;函数来读取数据：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;API: 
distorted_inputs(data_dir, batch_size)

args:
data_dir - 数据文件存放的路径，即‘cifar-10-batches-bin’文件夹
batch_size - 每次训练的图片数量

return：
images - batch_size个图片数据，shape为[batch_size, height, width, depth]
labels - batch_size个标签，shape为[batch_size]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;函数中的具体步骤：&lt;/p&gt;

&lt;p&gt;1) 解析路径&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 从该路径下的哪几个文件中获取数据
filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in xrange(1,6)]
# 监测这些文件是否存在
for f in filenames:
    if not tf.gfile.Exists(f):
        raise ValueError('Failed to find file: ' + f)
# 生成一个先入先出的队列，文件阅读器会通过它来读取数据。
filename_queue = tf.train.string_input_producer(filenames)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2) 把这些文件中读出来的二进制内容封装成图片&lt;/p&gt;

&lt;p&gt;自定义一个&lt;code class=&quot;highlighter-rouge&quot;&gt;read_cifar10&lt;/code&gt;函数来进行图片封装操作，具体如何封装的等下说&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;read_input = read_cifar10(filename_queue)
reshaped_image = tf.cast(read_input.uint8image, tf.float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;3) 为增加数据量，可以对图片进行“反转”、“平移”、“镜像”等操作&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
distorted_image = tf.image.random_flip_left_right(distorted_image)
distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)
distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)
float_image = tf.image.per_image_whitening(distorted_image)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;4) 把读取出来的图片送入队列中，直到队列中有足够多的图片时，随机输出batch_size个图片&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;return _generate_image_and_label_batch(float_image, read_input.label, min_queue_examples, batch_size, shuffle=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;自定义的&lt;code class=&quot;highlighter-rouge&quot;&gt;_generate_image_and_label_batch(...)&lt;/code&gt;函数就是用来产生batch_size个图像的，等下细说。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;图片封装 - read_cifar10&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;文件中的数据是二进制的，我们先把这些数据包装成图片。&lt;/p&gt;

&lt;p&gt;1) 声明一个一定大小的文件阅读器，大小为一张图画的大小。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2) 从文件中读出一张读片的数据，并转换类型，因为文件读取器读出来的是string类型的，我们需要转换成int类型的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result.key, value = reader.read(filename_queue) 
record_bytes = tf.decode_raw(value, tf.uint8)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;key - 该图片在文件中的index&lt;/p&gt;

&lt;p&gt;value - 该图片数据，包括图片本身的pixels以及标签label&lt;/p&gt;

&lt;p&gt;3) 把label和pixels分离开来&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result.label = tf.cast(tf.slice(record_bytes, [0], [label_bytes]), tf.int32)
depth_major = tf.reshape(tf.slice(record_bytes, [label_bytes], [image_bytes]), [result.depth, result.height, result.width])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里可能会有疑惑，为什么是这样分离的呢？
我们来看一下cifar-10官方网站上的说明就很明显了：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The binary version contains the files data_batch_1.bin, data_batch_2.bin, …, data_batch_5.bin, as well as test_batch.bin. Each of these files is formatted as follows:&lt;/p&gt;

  &lt;p&gt;&amp;lt;1 x label&amp;gt;&amp;lt;3072 x pixel&amp;gt;&lt;/p&gt;

  &lt;p&gt;…&lt;/p&gt;

  &lt;p&gt;&amp;lt;1 x label&amp;gt;&amp;lt;3072 x pixel&amp;gt;&lt;/p&gt;

  &lt;p&gt;In other words, the first byte is the label of the first image, which is a number in the range 0-9. The next 3072 bytes are the values of the pixels of the image. The first 1024 bytes are the red channel values, the next 1024 the green, and the final 1024 the blue. The values are stored in row-major order, so the first 32 bytes are the red channel values of the first row of the image.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所以，第一个数字就是label，后面的3072个数字，其实是这样组合的:&lt;/p&gt;

&lt;p&gt;[[red:1024], [green:1024], [blue:1024]] - 所以，reshape时候，第一维度是depth&lt;/p&gt;

&lt;p&gt;在看其中一个色度中：&lt;/p&gt;

&lt;p&gt;[red:1024] =&amp;gt; [[row1:32], [row2:32], …, [row32:32]] - 所以，第二维度是height，最后一个维度是width（即row）&lt;/p&gt;

&lt;p&gt;所以reshape之后，图片的形状是：[depth, height, width]&lt;/p&gt;

&lt;p&gt;4) 把图片本身转成[height, width, depth]形状&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result.uint8image = tf.transpose(depth_major, [1, 2, 0])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;batch_size个图像的生成 - _generate_image_and_label_batch&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;API: 
_generate_image_and_label_batch(image, label, min_queue_examples, batch_size, shuffle)

args:
image - 要送入队列的单张图片
label - 这张图片对应的标签
min_queue_examples - 队列中可容纳的数据量
batch_size - 要返回的图片数量
shuffle - 是否随机返回batch_size个图片

return：
images - batch_size个图片数据，shape为[batch_size, height, width, depth]
labels - batch_size个标签，shape为[batch_size]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个其实就是调用了一下本文最开头讲的&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.train.shuffle_batch(...)&lt;/code&gt;这个函数，这个函数会把单张图片放进队列中，然后当队列中有足够的图片时，就随机返回batch_size个图片。&lt;/p&gt;

&lt;p&gt;如果shuffle为False，则调用&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.train.batch(...)&lt;/code&gt;这个函数，和&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.train.shuffle_batch(...)&lt;/code&gt;类似，只是返回batch_size个图片的时候，不是随机的，而是顺序地输出。&lt;/p&gt;

&lt;p&gt;OK，至此为止，核心代码都讲过了，剩下的都是重复的或者很简单的，就不多说了。&lt;/p&gt;

</description>
        <pubDate>Fri, 25 Nov 2016 18:35:49 +0800</pubDate>
        <link>http://localhost:4000/machine_learning/posts/2016/11/25/maching-learning-tensorflow-6/</link>
        <guid isPermaLink="true">http://localhost:4000/machine_learning/posts/2016/11/25/maching-learning-tensorflow-6/</guid>
        
        
        <category>machine_learning</category>
        
        <category>posts</category>
        
      </item>
    
      <item>
        <title>TensorFlow卷积神经网络搭建（CIFAR10）</title>
        <description>&lt;p&gt;官方教程的CNN网络，识别CIFAR10数据集&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ShengleiH/machine_learning/blob/master/tensorflow/tutorials/cifar10/cifar10_model.py&quot;&gt;cifar10的cnn代码&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章将使用“敏捷开发模型”来写……顾名思义，从最主要的部分“网络结构”开始写，然后自定义一些方法，如“数据的读取”，假设这些方法已经可用，最后再去补充这些方法。个人感觉，这样由主要到次要，慢慢补充才能捕获整个结构。最后的最后，再来看如何使用TensorBoard可视化整个过程，所以开始的代码中，省略了所有的summary。&lt;/p&gt;

&lt;h3 id=&quot;cnn&quot;&gt;CNN网络搭建&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;CNN网络结构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;输入的图像shape为 [batch_size, height, width, depth]&lt;/p&gt;

&lt;p&gt;第一层：卷积层 conv1&lt;/p&gt;

&lt;p&gt;第二层：池化层 pool1&lt;/p&gt;

&lt;p&gt;第三层：标准化层 norm1&lt;/p&gt;

&lt;p&gt;第四层：卷积层 conv2&lt;/p&gt;

&lt;p&gt;第五层：标准化层 norm2&lt;/p&gt;

&lt;p&gt;第六层：池化层 pool2&lt;/p&gt;

&lt;p&gt;第七层：全联接层 local1&lt;/p&gt;

&lt;p&gt;第八层：全联接层 local2&lt;/p&gt;

&lt;p&gt;第九层：输出层 softmax_linear&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def inference(images_after_reshape):
    # convolution layer 1
    with tf.variable_scope('conv1') as conv1_scope:
        kernel = _variable_with_weight_decay('weights', shape=[5,5,3,64], stddev=5e-2, wd=0.0)
        conv = tf.nn.conv2d(images_after_reshape, kernel, strides=[1,1,1,1], padding='SAME')
        biases = _variable_on_cpu('biases', shape=[64], initializer=tf.constant_initializer(0.0))
        conv = tf.nn.bias_add(conv, bias=biases)
        conv1 = tf.nn.relu(conv, name=conv1_scope.name)

    # pooling layer
    pool1 = tf.nn.max_pool(conv1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME', name='pool1')

    # normalization
    norm1 = tf.nn.lrn(pool1, depth_radius=4, bias=1.0, alpha=0.001/9.0, beta=0.75, name='norm1')

    # convolution layer 2
    with tf.variable_scope('conv2') as conv2_scope:
        kernel = _variable_with_weight_decay('weights', shape=[5,5,64,64], stddev=5e-2, wd=0.0)
        conv = tf.nn.conv2d(norm1, kernel, strides=[1,1,1,1], padding='SAME')
        biases = _variable_on_cpu('biases', shape=[64], initializer=tf.constant_initializer(0.1))
        conv = tf.nn.bias_add(conv, bias=biases)
        conv2 = tf.nn.relu(conv, name=conv2_scope.name)

    # normalization
    norm2 = tf.nn.lrn(conv2, depth_radius=4, bias=1.0, alpha=0.001/9.0, beta=0.75, name='norm2')

    # pooling layer
    pool2 = tf.nn.max_pool(norm2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME', name='pool2')

    # fully connected layer 1
    with tf.variable_scope('local1') as local1_scope:
        images_as_long_vector = tf.reshape(pool2, shape=[FLAGS.batch_size, -1])
        input_neurons = images_as_long_vector.get_shape()[1].value
        weights = _variable_with_weight_decay('weights', shape=[input_neurons, 384], stddev=0.04, wd=0.004)
        biases = _variable_on_cpu('biases', shape=[384], initializer=tf.constant_initializer(0.1))
        local1 = tf.nn.relu(tf.matmul(images_as_long_vector, weights) + biases, name=local1_scope.name)

    # fully connected layer 2
    with tf.variable_scope('local2') as local2_scope:
        weights = _variable_with_weight_decay('weights', shape=[384, 192], stddev=0.04, wd=0.004)
        biases = _variable_on_cpu('biases', shape=[192], initializer=tf.constant_initializer(0.1))
        local1 = tf.nn.relu(tf.matmul(local1, weights) + biases, name=local2_scope.name)

    # output layer - softmax layer
    with tf.variable_scope('softmax_linear') as softmax_scope:
        weights = _variable_with_weight_decay('weights', shape=[192, NUM_CLASSES], stddev=1/192.0, wd=0.0)
        biases = _variable_on_cpu('biases', shape=[NUM_CLASSES], initializer=tf.constant_initializer(0.0))
        softmax_linear = tf.add(tf.matmul(local1, weights) + biases, name=softmax_scope.name)

    return softmax_linear
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里，有三个地方时我们自己假设的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;假设输入图像的形状已经是[batch_size, height, width, depth]。具体如何让自己的图像变成这样的形状，稍后会讲。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;假设已经定义了&lt;code class=&quot;highlighter-rouge&quot;&gt;_variable_with_weight_decay(name, shape], stddev, wd)&lt;/code&gt;函数，该函数将返回含有惩罚项（如L2, L1 loss）的权重。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;假设已经定义了&lt;code class=&quot;highlighter-rouge&quot;&gt;_variable_on_cpu(name, shape, initializer)&lt;/code&gt;函数，该函数将返回通过initializer获得的随机数。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;CNN网络loss计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了调整权重，我们需要有一个loss function来评估网络的好坏。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def loss(logits, labels):
    labels = tf.cast(labels, tf.int64)
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy_per_example')
    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')
    tf.add_to_collection('losses', cross_entropy_mean)
    total_loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return total_loss
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;logits：就是CNN网络，即inference()函数的返回值。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.add_to_collection('losses', cross_entropy_mean)&lt;/code&gt;：losses这个collection中除了有&lt;code class=&quot;highlighter-rouge&quot;&gt;cross_entropy_mean&lt;/code&gt;，还有&lt;code class=&quot;highlighter-rouge&quot;&gt;weight_decay&lt;/code&gt;这是在
定义&lt;code class=&quot;highlighter-rouge&quot;&gt;_variable_with_weight_decay&lt;/code&gt;时加进去的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.add_n&lt;/code&gt;：就是把losses这个collection中的&lt;code class=&quot;highlighter-rouge&quot;&gt;cross_entropy_mean&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;weight_decay&lt;/code&gt;取出来，然后相加，这样就形成了含有惩罚项(L2 or L1)的损失函数。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;CNN网络权重调整–梯度下降&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在定义了损失函数之后，我们将一边使用这个损失函数评估网络，一边使用梯度下降法(GD)来调整网络中的权重和偏置们。&lt;/p&gt;

&lt;p&gt;梯度下降法的使用，分为两步–1.每一个权重的梯度gradient；2.根据learning rate，使用梯度下降法调整权重。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def train(total_loss, global_step):
    # Variables that affect learning rate.
    num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size
    decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)

    # Decay the learning rate exponentially based on the number of steps.
    lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE, global_step, decay_steps, LEARNING_RATE_DECAY_FACTOR, staircase=True)

    # Begin training
    optimizer = tf.train.GradientDescentOptimizer(lr)
    grads = optimizer.compute_gradients(total_loss)
    train_op = optimizer.apply_gradients(grads, global_step=global_step)
    return train_op
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里由于我们不知道合适的learning rate是多少，所以我们动态地调整lr，画出曲线（如何画出曲线，稍后再说，这里把画曲线的代码省略了），然后最后选取最合适的lr。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;开始补充自定义方法&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;初始化权重&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def _variable_with_weight_decay(name, shape, stddev, wd):
    dtype = tf.float16 if FLAGS.use_fp16 else tf.float32
    var = _variable_on_cpu(
        name,
        shape,
        tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))
    if wd is not None:
        weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')
        tf.add_to_collection('losses', weight_decay)
    return var


def _variable_on_cpu(name, shape, initializer):
    dtype = tf.float16 if FLAGS.use_fp16 else tf.float32
    var = tf.get_variable(name, shape=shape, dtype=dtype, initializer=initializer)
    return var
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这两个自定义函数中，&lt;code class=&quot;highlighter-rouge&quot;&gt;_variable_on_cpu&lt;/code&gt;很好理解，就是根据提供的initializer来随机生成一些数。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;_variable_with_weight_decay&lt;/code&gt;中主要是两个参数stddev和wd：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;stddev：因为这个函数中用的initializer是“截断高斯分布”，需要提供一个“标准差”来确定这个分布。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;wd：weight_decay。这是惩罚项系数，就是乘在L2, L1 loss前面的那个系数。如果wd=0.0，就意味着，不要惩罚项。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可见，weights的初始化都用到了weight_dacay，而biases的初始化不需要weight_decay。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;图像数据的读取和reshape&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将在下一篇中讲到，因为比较复杂。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/r0.11/tensorflow/models/image/cifar10&quot;&gt;TensorFlow官方tutorial-cnn-github&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 25 Nov 2016 17:34:49 +0800</pubDate>
        <link>http://localhost:4000/machine_learning/posts/2016/11/25/maching-learning-tensorflow-5/</link>
        <guid isPermaLink="true">http://localhost:4000/machine_learning/posts/2016/11/25/maching-learning-tensorflow-5/</guid>
        
        
        <category>machine_learning</category>
        
        <category>posts</category>
        
      </item>
    
      <item>
        <title>IRIS flowers识别（TensorFlow.contrib.learn）</title>
        <description>&lt;p&gt;官方教程的第四篇，识别IRIS flowers&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ShengleiH/machine_learning/blob/master/tensorflow/tutorials/iris_flowers&quot;&gt;iris代码&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;使用了tensorflow.contrib.learn中已经分装好的神经网络。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;包的导入&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf
import numpy as np
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;import numpy：接下来有用到numpy中的数据类型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;下载数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;把iris flowers的csv文件下载下来，这里把文件放在和神经网络同一文件夹下，所以路径直接是文件名称就可以了，不然的话就需要调整一下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;IRIS_TRAINING = &quot;iris_training.csv&quot;
IRIS_TEST = &quot;iris_test.csv&quot;

training_set = tf.contrib.learn.datasets.base.load_csv_with_header(filename=IRIS_TRAINING, features_dtype=np.float, target_dtype=np.int)
test_set = tf.contrib.learn.datasets.base.load_csv_with_header(filename=IRIS_TEST, features_dtype=np.float, target_dtype=np.int)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里需要注意，官方的tutorials中有错误，tensorflow更新了，但是教程没有及时更新。
官方tutorials中给的代码中使用的是&lt;code class=&quot;highlighter-rouge&quot;&gt;load_csv()&lt;/code&gt;，但是在目前最新版本的tensorflow中已经把load_csv()给移除了，取而代之的是&lt;code class=&quot;highlighter-rouge&quot;&gt;load_csv_with_header(filename,
                         target_dtype,
                         features_dtype,
                         target_column=-1)&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;load_csv_without_header(filename,
                            target_dtype,
                            features_dtype,
                            target_column=-1)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;github上有这两个函数的&lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/fcab4308002412e38c1a6d5c6145119f04540d45/tensorflow/contrib/learn/python/learn/datasets/base.py#L38&quot;&gt;源代码&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;配置网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;tf.contrib.learn.DNNClassifier中已经把网络的框架封装完毕，只需要我们传入“特征配置”、“每一层节点数量”、“目标分类数”和”checkpoint data存放的路径“即可。&lt;/p&gt;

&lt;p&gt;特征配置：设定特征的数据类型-这里符合“real_valued_column”，然后一共有4个特征，所以dimension=4&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 特征配置
feature_columns = [tf.contrib.layers.real_valued_column(&quot;&quot;, dimension=4)]
# 配置网络
classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3, model_dir=&quot;/tmp/iris_model&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;训练网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直接调用fit函数即可，参数为训练数据、其对应的labels以及需要迭代的次数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;classifier.fit(x=training_set.data, y=training_set.target, steps=2000)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;评估网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直接调用evaluate函数即可，参数为测试数据。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;accuracy_score = classifier.evaluate(x=test_set.data, y=test_set.target)[&quot;accuracy&quot;]
print('Accuracy: {0:f}'.format(accuracy_score))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最终结果为：Accuracy: 0.966667&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;预测数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用numpy.array模拟两个数据，然后调用predict函数预测模拟数据的labels&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;new_samples = np.array([[6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]], dtype=float)
y = classifier.predict(new_samples)
print('Predictions: {}'.format(str(y)))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;结果为：Predictions: [1 2]&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/versions/r0.11/tutorials/tflearn/index.html&quot;&gt;TensorFlow官方tutorial-iris&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/40007785/why-tensor-flow-could-not-load-csv&quot;&gt;StackOverFlow-load_csv&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 12 Nov 2016 14:10:49 +0800</pubDate>
        <link>http://localhost:4000/machine_learning/posts/2016/11/12/maching-learning-tensorflow-4/</link>
        <guid isPermaLink="true">http://localhost:4000/machine_learning/posts/2016/11/12/maching-learning-tensorflow-4/</guid>
        
        
        <category>machine_learning</category>
        
        <category>posts</category>
        
      </item>
    
      <item>
        <title>结构化的全连接神经网络FNN框架--part2使用（TensorFlow）</title>
        <description>&lt;p&gt;这一篇中我们将使用前面搭建的FNN网络来训练MNIST数据集&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ShengleiH/machine_learning/blob/master/tensorflow/tutorials/encapsulatedFNN/fully_connected_feed.py&quot;&gt;使用FNN代码&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里不进行整篇代码的详细解释，只对其中几个我疑惑的地方进行解释。&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;几个包的导入&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from __future__ import division

import os.path
import time

import tensorflow as tf

from tensorflow.examples.tutorials.mnist import input_data
import naiveFNN

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;from __future__ import division：为了使用’//’，整除，结果为不大于真是结果的整数。如果不引入这个包，就会默认为’/’就是除法。&lt;/p&gt;

&lt;p&gt;import os.path：为了使用&lt;code class=&quot;highlighter-rouge&quot;&gt;checkpoint_file = os.path.join(FLAGS.train_dir, 'checkpoint')&lt;/code&gt;这是用来记录每一步的日志，和网络本身没啥关系。&lt;/p&gt;

&lt;p&gt;import time：为了使用&lt;code class=&quot;highlighter-rouge&quot;&gt;start_time = time.time()&lt;/code&gt;这是用来获取迭代时间的，和网络本身没有关系&lt;/p&gt;

&lt;p&gt;import tensorflow as tf：为了使用tensorflow中的方法&lt;/p&gt;

&lt;p&gt;from tensorflow.examples.tutorials.mnist import input_data：从官网github上下载实验所需数据集，如果自行下载了，和代码放在同一目录下，然后直接import input_data就好了。&lt;/p&gt;

&lt;p&gt;import naiveFNN：使用FNN网络框架。这里要注意，如果要运行代码，请务必将naiveFNN.py下载，并且和这个代码放在同一目录下。&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;网络各层参数定义&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;flags = tf.app.flags
flags.DEFINE_float('learning_rate', 0.1, 'Initial learning rate.')
flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.')
flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.')
flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')
flags.DEFINE_integer('batch_size', 100, 'Batch size. Must divide evenly into the dataset sizes.')
flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.')
flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data for unit testing.')
FLAGS = flags.FLAGS
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里的FLAGS，我的理解就是和java中的枚举类似，之后调用的时候就直接&lt;code class=&quot;highlighter-rouge&quot;&gt;FLAGS.balabala&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我的额外理解&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一开始我感觉很奇怪，为什么train_dir的值会是data，前面的实验中我们都使用的是MNIST_data，难道这可以随便设吗？&lt;/p&gt;

&lt;p&gt;后来我去翻了下Dataset.read_data_sets(…)方法的源代码（已经在你电脑中的python下面了哦）:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;local_file = base.maybe_download(TRAIN_IMAGES, train_dir, SOURCE_URL + TRAIN_IMAGES)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;继续去base.maybe_download(…)源代码查看：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def maybe_download(filename, work_directory, source_url):
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可见，这只是一个work directory，也就是在本地，你要把下载下来的数据存放的地方，如果这个directory不存在，就创建一个，如果存在，就放在这个下面。真正决定从哪里下载的是source_url。filename也只是这些数据集在本地的命名。&lt;/p&gt;

&lt;h4 id=&quot;runtraining&quot;&gt;在run_training函数中给框架填充数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;logits = naiveFNN.inference(images_placeholder, FLAGS.hidden1, FLAGS.hidden2)
loss = naiveFNN.loss(logits, labels_placeholder)
train_op = naiveFNN.training(loss, FLAGS.learning_rate)
eval_correct = naiveFNN.evaluation(logits, labels_placeholder)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;runtraining-1&quot;&gt;在run_training函数中训练网络&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for step in xrange(FLAGS.max_steps):
    feed_dict = fill_feed_dict(data_sets.train, images_placeholder, labels_placeholder)
    _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;迭代FLAGS.max_steps次，每次去batch_size个数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我的额外理解&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;fill_feed_dict：自定义的一个用来向placehoder中填充数据的函数，从data_sets.train中取出数据，填充到images_placeholder, labels_placeholder中，然后返回一个包含了这两个placeholders的dictionary。&lt;/p&gt;

&lt;p&gt;sess.run([train_op, loss], feed_dict=feed_dict)：写成&lt;code class=&quot;highlighter-rouge&quot;&gt;sess.run([train_op, loss], feed_dict)&lt;/code&gt;也可以的，有没有&lt;code class=&quot;highlighter-rouge&quot;&gt;feed_dict=&lt;/code&gt;这个无所谓。这个函数是前面第一个参数是什么，它就返回什么，比如说，第一个参数是[train_op, loss]，那么就会返回[train_op, loss]，然后因为train_op的值我们不需要，所以就用’_‘来忽略，loss的结果就用loss_value来接收。&lt;/p&gt;

&lt;p&gt;xrange：作用和range是一样的，但是在大数据集时，xrange的性能更好。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;range(5)
[0, 1, 2, 3, 4]

xrange(5)
list(xrange(5))
[0, 1, 2, 3, 4]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;最后整理一下run_training的整个步骤&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从train set中取batch_size个数据并填充到网络中&lt;/li&gt;
  &lt;li&gt;运行网络，获取网络的loss值&lt;/li&gt;
  &lt;li&gt;继续步骤1、2，直到循环“max_steps”次（只是网络的累积调整过程，每一次都是在上一次的基础上进行的）&lt;/li&gt;
  &lt;li&gt;每100次循环输出一个loss value看看&lt;/li&gt;
  &lt;li&gt;每999次循环以及&lt;strong&gt;最后一次循环&lt;/strong&gt;，对当前网络进行一个测评：
    &lt;ol&gt;
      &lt;li&gt;从train／validation／test数据集中取batch_size个数据&lt;/li&gt;
      &lt;li&gt;运行测评网络（naiveFNN.evaluation()那个函数），获取这batch_size个数据中正确的个数&lt;/li&gt;
      &lt;li&gt;继续步骤1、2，直到循环“数据集总个数//batch_size”次（这里‘//’是一个整除）。循环的目的是为了尽可能地用尽数据集中的数据。&lt;/li&gt;
      &lt;li&gt;最后获取到train／validation／test数据集中判断正确的个数&lt;/li&gt;
      &lt;li&gt;计算得到准确率&lt;code class=&quot;highlighter-rouge&quot;&gt;precision = true_count / num_examples&lt;/code&gt;。由于整除这里的num_examples可能比实际的少&lt;code class=&quot;highlighter-rouge&quot;&gt;num_examples = real_num_examples // batch_size * FLAGS.batch_size&lt;/code&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;于是在&lt;strong&gt;最后一次循环&lt;/strong&gt;后，我们获取到了一个准确率precision&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;OK，以上就是用TensorFlow搭建封装的神经网络的解析。很多API还是没有理解好，不过不急，慢慢地用多了就有感觉了，就会知道了。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;a href=&quot;https://www.tensorflow.org/versions/r0.11/tutorials/mnist/tf/index.html#tensorflow-mechanics-101&quot;&gt;TensorFlow官方tutorial-mechanics-101&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 10 Nov 2016 14:10:49 +0800</pubDate>
        <link>http://localhost:4000/machine_learning/posts/2016/11/10/maching-learning-tensorflow-3/</link>
        <guid isPermaLink="true">http://localhost:4000/machine_learning/posts/2016/11/10/maching-learning-tensorflow-3/</guid>
        
        
        <category>machine_learning</category>
        
        <category>posts</category>
        
      </item>
    
      <item>
        <title>结构化的全连接神经网络FNN框架--Part1搭建（TensorFlow）</title>
        <description>&lt;p&gt;上一篇中的全连接神经网络上是不具有代码重用性的，这样零散的结构不太符合object-oriented规范。今天照着tutorial里给的代码重写了一遍，理解了其中的一些，还有一些依旧难以理解，可能是对python语法也不太熟悉的缘故。&lt;/p&gt;

&lt;p&gt;先把自己理解了的写下来，即使花费宝贵的半小时睡眠时间也得写下来，今日事今日毕！&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ShengleiH/machine_learning/blob/master/tensorflow/tutorials/encapsulatedFNN/naiveFNN.py&quot;&gt;网络框架完整代码&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;神经网络框架的搭建在naiveFNN.py中完成，这里面没有任何数据，相当于定义了一个巨型函数，所有的数据都在后续使用中填充，而naiveFNN.py单纯地构建一个&lt;strong&gt;框架&lt;/strong&gt;（或称为函数）&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;首先强调一点：TensorFlow中，图片的所有输入和输出shape都是[batch_size, NUM_nuerons]；输入[55000, 784]，输出[55000, 10]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;inference---tensorflowgraph&quot;&gt;inference 推理函数–用来构建出网络雏形（在tensorflow中把这个网络结构称为graph，图）：&lt;/h4&gt;

&lt;p&gt;这里我们构建一个4层的神经网络，输入层[784个nuerons]、隐藏层1（hidden1）、隐藏层2（hidden2）和输出层（softmax_linear）&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def weights_varialble(shape, input_units):
    initial = tf.truncated_normal(shape, stddev=1.0/math.sqrt(float(input_units)))
    return tf.Variable(initial, name='weights')


def biases_variable(shape):
    initial = tf.zeros(shape)
    return tf.Variable(initial, name='biases')
    
    
def inference(images, hidden1_units, hidden2_units):
    with tf.name_scope('hidden1'):
        weights = weights_varialble([IMAGE_PIXELS, hidden1_units], IMAGE_PIXELS)
        biases = biases_variable([hidden1_units])
        hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)

    with tf.name_scope('hidden2'):
        weights = weights_varialble([hidden1_units, hidden2_units], hidden1_units)
        biases = biases_variable([hidden2_units])
        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)

    with tf.name_scope('softmax_linear'):
        weights = weights_varialble([hidden2_units, NUM_CLASSES], hidden2_units)
        biases = biases_variable([NUM_CLASSES])
        logits = tf.matmul(hidden2, weights) + biases

    return logits
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;来看下这个函数的参数（args）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;images：输入的图片集–训练集、测试集……形状（shape）为[batch_size, IMAGE_PIXELS]，如[50, 784]&lt;/p&gt;

&lt;p&gt;hidden1_units, hidden2_units：这两层的neuron数量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我的额外理解：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;with tf.name_scope(‘hidden1’)：就是在名为hidden1的范围下定义了下面的这些东西：weights、biases和hidden1，所有的这些东西都是属于hidden1的。&lt;/li&gt;
  &lt;li&gt;这里weights和biases的初始化的函数不一定是这样的，如biases的初始化还可以用上一篇中的：&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.constant(0.1, shape=shape)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;还需要注意的，tensorflow中，matmul函数中参数的顺序，理论学习中我们知道应该是&lt;code class=&quot;highlighter-rouge&quot;&gt;y = Wx + b&lt;/code&gt;，而这里matmul中的顺序是相反的–&lt;code class=&quot;highlighter-rouge&quot;&gt;matmul(x, W)&lt;/code&gt;。其实我发现，tensorflow中矩阵的行列和理论学习中的都是相反的……&lt;/li&gt;
  &lt;li&gt;这里输出层softmax_linear没有使用调用softmax函数，是因为tensorflow中有这样的函数可以一边对数据apply softmax，一边进行计算交叉熵cross_entropy（简写xentropy），我们在下一步的loss函数中会用到的–sparse_softmax_cross_entropy_with_logits(…)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;我的问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;name_scope中定义的变量可以在这个范围之外被读取到吗？如果说不能，那么上面代码中，&lt;code class=&quot;highlighter-rouge&quot;&gt;return logits&lt;/code&gt;是怎么来的？如果说能，那么上面代码中，hidden1和hidden2中都有weights和biases这可怎么区分啊？？？&lt;/p&gt;

&lt;h4 id=&quot;loss---&quot;&gt;loss 损失函数–用来向雏形图中添加“损失操作”&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def loss(logits, labels):
    labels = tf.to_int64(labels)
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name='xentropy')
    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')
    return loss
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;来看下这个函数的参数（args）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;logits：是我们在inference中构建好的网络雏形，或者说也是网络最后输出层的结果。我觉得这两种理解都行，更偏向于第一种理解，个人感觉这个和matlab中CNN搭建时候很像–建立一个雏形网络，要向里面加东西的时候，就把这个雏形网络作为参数传进去。&lt;/p&gt;

&lt;p&gt;labels：图片数据集的标签集，&lt;code class=&quot;highlighter-rouge&quot;&gt;shape = [batch_size, NUM_CLASSES]&lt;/code&gt;。官网上说，这个集合必须是one-hot value，也就是说，如果这张图片中的数字是3，那么它的标签就得是[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]。这里把labels传进来肯定是非常必要的，因为你要根据这个正确的labels来判断你的网络好不好，然后back propagation来调整你的weights和biases呀！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我的额外理解：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss = tf.reduce_mean(...)&lt;/code&gt;，其实直接&lt;code class=&quot;highlighter-rouge&quot;&gt;loss = cross_entropy&lt;/code&gt;也是没有啥关系的。只不过后面的learning rate调整得小一些就行啦，为什么呢？我是这样理解的：learning rate是每次梯度下降的步长，&lt;strong&gt;learning rate越小&lt;/strong&gt;，梯度下降越慢，是一点儿一点，不敢懈怠地在下降，生动地说，就是&lt;strong&gt;学习得相当仔细&lt;/strong&gt;。而我们的终极目标就是要减小loss到一个范围内，如果取均值，那么loss一开始就比较小了，于是learning rate可以相对大一些，也就是说学习得稍微粗略一些，也能在规定的时间（即迭代次数）内把loss减小到范围内；如果不取均值，那么loss一开始是比较大的，如果要在规定时间（即迭代次数）内把loss下降到一定的范围内，就要学习得仔细一点儿，即让learning rate相对小一些。个人理解，应该不太准确。&lt;/li&gt;
  &lt;li&gt;这里用了&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.sparse_softmax_cross_entropy_with_logits(...)&lt;/code&gt;，用其他的也是可以的，比如说上一篇中用的&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.softmax_cross_entropy_with_logits(...)&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;我的问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我看了半天也没有看出来官网给的代码中的labels怎么就突然成了one-hot value了，因为它的代码中并没有如下转换代码，而且数据本身也不是one-hot value啊。&lt;/p&gt;

&lt;p&gt;tutorials里面给了这段代码，可以让labels都变成one-hot value：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;batch_size = tf.size(labels)
labels = tf.expand_dims(labels, 1)
indices = tf.expand_dims(tf.range(0, batch_size, 1), 1)
concated = tf.concat(1, [indices, labels])
onehot_labels = tf.sparse_to_dense(concated, tf.pack([batch_size, NUM_CLASSES]), 1.0, 0.0)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;对tensorflow的tensor还不是很熟悉的我，真的很难想象tensor的dimension，我现在的唯一理解就是，第一维度就是最外层括号内有多少个整体（第二层括号或者数字），第二维度就是第二层括号内有几个整体（第三层括号或者数字），比如说[[],[],[],[]]的第一维度就是4，[[1,2,3],[3,2,1],[1,1,1],[2,2,2]]的第一维度是4，第二维度就是3。&lt;/p&gt;

&lt;p&gt;所以用代码把每一个步骤的结果打印出来。&lt;/p&gt;

&lt;p&gt;首先，假设&lt;code class=&quot;highlighter-rouge&quot;&gt;labels = [0, 3, 4, 1, 9]&lt;/code&gt;，那么转换过程如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf
session = tf.Session()

NUM_CLASSES = 10

labels = [0, 3, 4, 1, 9]
print(labels)
#输出结果：[0, 3, 4, 1, 9]

batch_size = tf.size(labels)
print(session.run(batch_size))
#输出结果：5

labels = tf.expand_dims(labels, 1)
print(session.run(labels))
#输出结果：
[[0]
 [3]
 [4]
 [1]
 [9]]

range = tf.range(0, batch_size, 1)
print(session.run(range))
#输出结果：[0 1 2 3 4]

indices = tf.expand_dims(range, 1)
print(session.run(indices))
#输出结果：
[[0]
 [1]
 [2]
 [3]
 [4]]

concated = tf.concat(1, [indices, labels])
print(session.run(concated))
#输出结果：
[[0 0]
 [1 3]
 [2 4]
 [3 1]
 [4 9]]

pack = tf.pack([batch_size, NUM_CLASSES])
print(session.run(pack))
#输出结果：
[ 5 10]

onehot_labels = tf.sparse_to_dense(concated, pack, 1.0, 0.0)
print(session.run(onehot_labels))
#输出结果：
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;training---&quot;&gt;training 训练函数–用来向网络中（图中）添加“梯度下降”操作，故名“训练”&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def training(loss, learning_rate):
    tf.scalar_summary(loss.op.name, loss)
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    global_step = tf.Variable(0, name='global_step', trainable=False)
    train_op = optimizer.minimize(loss, global_step=global_step)
    return train_op
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;来看下这个函数的参数（args）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;loss：添加了“损失函数”的网络，或者是这个网络的损失值。&lt;/p&gt;

&lt;p&gt;learning_rate：学习率。说了这个函数是用梯度下降来训练网络的，所以学习率是必须的，也是人为规定的，所以作为参数输入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我的额外理解：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;这里影响网络的是后面三行，第一行不影响，只是为了接下来的可视化做了一个监测。&lt;/li&gt;
  &lt;li&gt;optimizer.minimize更新了loss网络中的weights和biases，还更新了global_step（当前是第几次梯度下降）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;我的问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;看不懂tf.scalar_summary的用法，说是这个可以把每一次的结果都实时地添加，然后就可以用TensorBoard来可视化整个过程了。还没仔细看过。&lt;/p&gt;

&lt;h4 id=&quot;evaluation---inference&quot;&gt;evaluation 评估函数–用来向&lt;strong&gt;inference&lt;/strong&gt;函数构造的雏形网络中（图中）添加“评估函数”&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def evaluation(logits, labels):
    correct = tf.nn.in_top_k(logits, labels, 1)
    return tf.reduce_sum(tf.cast(correct, tf.int32))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;来看下这个函数的参数（args）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;logits：是我们在inference中构建好的网络雏形，或者说也是网络最后输出层的结果。&lt;/p&gt;

&lt;p&gt;labels：图片数据集的标签集，是one-hot value，&lt;code class=&quot;highlighter-rouge&quot;&gt;shape = [batch_size, NUM_CLASSES]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我的额外理解：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.in_top_k(predictions, targets, k)&lt;/code&gt;：predictions是&lt;code class=&quot;highlighter-rouge&quot;&gt;type = float32; shape = [batch_size, NUM_CLASSES]&lt;/code&gt;的矩阵，其中的值代表这个图像被判定为该类别的概率，targets是&lt;code class=&quot;highlighter-rouge&quot;&gt;type = int32 or int64; shape = [batch_size]&lt;/code&gt;的向量，其中的值代表这个图像的真实类别index。k表示这个图像的真实类别的值在predictions的概率中排名前k个。如果排到了前k个，则true，否则false。这里由于predictions全是one-hot value的，一个图像在10个类别下只有一个为1.0，其余都为0.0，所以k=1才能够分类（想一下如果k=2的话，概率的前两名就是1.0和0.0，不管这个类别是什么，它的概率肯定是1.0或者0.0的，也就是说，不论类别是啥，都会是对的。）&lt;/li&gt;
  &lt;li&gt;in_top_k函数的返回值是bool类型的，我们先把它转换成int类型的，也就是非1即0这样的，然后加一下总和，就知道有几个1了，也就是有几个正确的结果了。&lt;/li&gt;
  &lt;li&gt;redeuce_sum(…)的reduce意味着在这个tensor的第几个维度上操作。比如说，一个矩阵（Tensor’s rank = 2），指定&lt;code class=&quot;highlighter-rouge&quot;&gt;dim = 0&lt;/code&gt;，则在第一维上求和，比如:&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = [[2, 3, 1], [2, 3, 1]]

tf.reduce\_sum(x, 0)的结果就是：x = [[2, 3, 1]+[2, 3, 1]] = [4, 6, 2]
 
tf.reduce\_sum(x, 1)的结果就是：x = [[2+3+1], [2+3+1]] = [6, 6]
 
tf.reduce\_sum(x, -1) = tf.reduce\_sum(x, 0)
 
tf.reduce\_sum(x, -2) = tf.reduce\_sum(x, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;我的问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个没有啥问题……&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;下一篇中我们将填充数据，也就是官网代码中的fully_connected_feed.py中的代码&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;参考资料：&lt;a href=&quot;https://www.tensorflow.org/versions/r0.11/tutorials/mnist/tf/index.html#tensorflow-mechanics-101&quot;&gt;TensorFlow官方tutorial-mechanics-101&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 09 Nov 2016 22:15:50 +0800</pubDate>
        <link>http://localhost:4000/machine_learning/posts/2016/11/09/maching-learning-tensorflow-2/</link>
        <guid isPermaLink="true">http://localhost:4000/machine_learning/posts/2016/11/09/maching-learning-tensorflow-2/</guid>
        
        
        <category>machine_learning</category>
        
        <category>posts</category>
        
      </item>
    
      <item>
        <title>使用TensorFlow搭建最简单的全连接神经网络</title>
        <description>&lt;p&gt;前几天看了TensorFlow，今天把之前写的“三层全连接神经网络”重新写了一遍，然后发现了一个问题，最后自己解决啦～&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ShengleiH/machine_learning/blob/master/tensorflow/tutorials/naiveNN.py&quot;&gt;3层全连接网络完整代码&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;神经网络的搭建&lt;/h4&gt;

&lt;h6 id=&quot;tensorflow&quot;&gt;导入tensorflow包：&lt;/h6&gt;
&lt;p&gt;这要是不导入怎么用啊？！&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h6 id=&quot;mnist&quot;&gt;加载MNIST数据&lt;/h6&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h6 id=&quot;section-1&quot;&gt;搭建空的网络框架&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;1. 定义好将来存放数据x和标签y的占位符placeholder&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2. 定义好用来初始化weights和bias的函数，然后定义好变量W和b&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def init_weights(shape):
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)

def init_bias(shape):
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial)

W1 = init_weights([784, 100])
b1 = init_bias([100])
W2 = init_weights([100, 10])
b2 = init_bias([10])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;3. 前向传播&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用relu函数作为激活函数，使用softmax作为分类器。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;y1 = tf.nn.relu(tf.matmul(x, W1) + b1)
y2 = tf.nn.softmax(tf.matmul(y1, W2) + b2)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4. 反向传播&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;tensorflow已经封装好了back propagation。
由于分类器使用了softmax，所以这里的代价函数是&lt;strong&gt;交叉熵（cross-entropy）&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y2), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;5. 模型评估&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;correct_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h6 id=&quot;section-2&quot;&gt;训练模型&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;1. 开启事务session，初始化刚才定义的变量&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;session = tf.InteractiveSession()
session.run(tf.initialize_all_variables())
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2. 赋值训练&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for i in range(1000):
    batch = mnist.train.next_batch(100)
    train_step.run(feed_dict={x: batch[0], y_: batch[1]})
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h6 id=&quot;section-3&quot;&gt;测试模型&lt;/h6&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-4&quot;&gt;我遇到的问题（解决了）&lt;/h4&gt;

&lt;p&gt;我发现的一个问题。&lt;/p&gt;

&lt;p&gt;每次在学习神经网络的时候，最搞不清楚的就是矩阵的维度，到底是nm？还是mn？这次在TensorFlow的代码中，也着实让我混乱了一把，因为它和我们理论学习中矩阵的维度是相反的！！！&lt;/p&gt;

&lt;p&gt;在这里我们搭建了一个3层的全连接神经网络：第一层输入层有784个nueron（即一张图片为28*28像素的）；第二层隐藏层有100个nueron（自己设置的，无所谓吧，应该）；第三层输出层有10个neuron（即标签的数量0–9，10个数字）&lt;/p&gt;

&lt;p&gt;于是在理论学习中，从输入层到隐藏层，我们会把&lt;strong&gt;输入图像矩阵&lt;/strong&gt;设置为&lt;strong&gt;784乘m&lt;/strong&gt;；&lt;strong&gt;权重矩阵&lt;/strong&gt;设置成&lt;strong&gt;100乘784&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;然而我们可以在代码中看到，TensorFlow是这样设置的：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])
W1 = init_weights([784, 100])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;也就是说，TensorFlow中把&lt;strong&gt;输入图像矩阵&lt;/strong&gt;设置为&lt;strong&gt;m乘784&lt;/strong&gt;；&lt;strong&gt;权重矩阵&lt;/strong&gt;设置成&lt;strong&gt;784乘100&lt;/strong&gt;,明显的，它的维度和我们理论学习中的是&lt;strong&gt;相反的&lt;/strong&gt;！！！&lt;/p&gt;

&lt;p&gt;那么我们在看&lt;strong&gt;模型评估&lt;/strong&gt;这里：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;correct_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;argmax函数是把指定维度中最大的那一个的index返回。&lt;/p&gt;

&lt;p&gt;前面代码中定义的placeholders中y_的shape是[None, 10]，也就是说y_的第一维度在TensorFlow中表示数据的index，第二维度才是计算出来的10个label的值呀。而在模型评估中，用了tf.argmax(y_, 1)，就是说对y_的第一维度取最大值？！这不就错了？不应该使用第二维度吗？即tf.argmax(y_, 2)？&lt;/p&gt;

&lt;p&gt;然后我就试了一下tf.argmax(y_, 2)，报错了！！！说“这个维度的取值在[0,2)”，于是，我明白了！TensorFlow中维度是从0开始算的！！！&lt;strong&gt;很好，这相当程序员！！！&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 05 Nov 2016 11:49:45 +0800</pubDate>
        <link>http://localhost:4000/machine_learning/posts/2016/11/05/maching-learning-tensorflow-1/</link>
        <guid isPermaLink="true">http://localhost:4000/machine_learning/posts/2016/11/05/maching-learning-tensorflow-1/</guid>
        
        
        <category>machine_learning</category>
        
        <category>posts</category>
        
      </item>
    
  </channel>
</rss>
